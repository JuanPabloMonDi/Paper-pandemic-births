#abline(h=qnorm(0.975)*sqrt(1/size))
#abline(h=-qnorm(0.975)*sqrt(1/size))
Plags<-Plags[abs(Plags$value)>qnorm(0.975)*sqrt(1/size),]
Plags<-Plags$lag
npp<-length(Plags)
pp<-rbind(pp,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(npp>=1, Plags[[length(Plags)]], 0),p2=ifelse(npp>=2, Plags[(length(Plags)-1)], 0),p3=ifelse(npp>=3, Plags[(length(Plags)-2)], 0)))
#For Spearman the variance is 1/(N-1)
#plot(corSpearman,type="h")
#abline(h=-qnorm(0.975)*sqrt(1/(size-1)))
#abline(h=qnorm(0.975)*sqrt(1/(size-1)))
SPlags<-data.frame(lag=(index(corSpearman)-1),value=corSpearman)
SPlags<-SPlags[abs(SPlags$value)>qnorm(0.975)*sqrt(1/(size-1)),]
SPlags<-SPlags$lag
nsp<-length(SPlags)
psp<-rbind(psp,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(nsp>=1, SPlags[[length(SPlags)]], 0),p2=ifelse(nsp>=2, SPlags[(length(SPlags)-1)], 0),p3=ifelse(nsp>=3, SPlags[(length(SPlags)-2)], 0)))
#For Kendall the variance is 2(2n+5)/9n(n-1)
#plot(corKendall[1:lag],type="h")
#abline(h=qnorm(0.975)*sqrt(2*(2*size+5)/(9*size*(size-1))))
#abline(h=-qnorm(0.975)*sqrt(2*(2*size+5)/(9*size*(size-1))))
Klags<-data.frame(lag=(index(corKendall)-1),value=corKendall)
Klags<-Klags[abs(Klags$value)>(qnorm(0.975)*sqrt(2*(2*size+5)/(9*size*(size-1)))),]
Klags<-Klags$lag
nk<-length(Klags)
pk<-rbind(pk,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(nk>=1, Klags[[length(Klags)]], 0),p2=ifelse(nk>=2, Klags[[(length(Klags)-1)]], 0),p3=ifelse(nk>=3, Klags[[(length(Klags)-2)]], 0)))
#For Xi the variance is 2/5N
#plot(corXi[1:lag],type="h")
#abline(h=qnorm(0.975)*sqrt(2/(5*size)),col="red",lw=1)
#abline(h=-qnorm(0.975)*sqrt(2/(5*size)),col="red",lw=1)
#Get the 3 maximum autocorrelations
Xilags<-data.frame(lag=(index(corXi)-1),value=corXi)
Xilags<-Xilags[abs(Xilags$value)>(qnorm(0.975)*sqrt(2/(5*size))),]
Xilags<-Xilags$lag#[(nrow(Xilags)-2):nrow(Xilags)]
nxi=length(Xilags)
pxi<-rbind(pxi,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(nxi>=1, Xilags[[length(Xilags)]], 0),p2=ifelse(nxi>=2, Xilags[[(length(Xilags)-1)]], 0),p3=ifelse(nxi>=3, Xilags[[(length(Xilags)-2)]], 0)))
#codecM<-append(codecM,codec(data[,1],data[,ncol(data)],data[,2:(ncol(data)-1)]))
#Now, with the coefficient of Azadka-Chatterjee
codecM<-foci(data$xt,data[2:(lag+1)],numCores = 1)
codecM<-codecM$selectedVar$index
ncodec=length(codecM)
pcodec<-rbind(pcodec,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(ncodec>=1, max(codecM), 0),p2=ifelse(ncodec>=2, sort(codecM, TRUE)[2], 0),p3=ifelse(ncodec>=3,sort(codecM, TRUE)[3], 0)))
} #End series iterations
} #End simulations
}#End sizes
update_progress((n_size-1)*(n_sim)*ncol(series)*lag.max+(sim-1)*lag.max*ncol(series) + (n_serie - 1)*lag.max + lag, length(sizes)*n_sim*ncol(series)*lag.max)
pp
View(pp)
7*5**3
7*5*3
#Fixed terms
n_sim=2
lag.max=21
pp=NULL
psp=NULL
pk=NULL
pxi=NULL
pcodec<-NULL
sizes<-c(100,200)
n_size=0
for (size in sizes){
n_size=n_size+1
#Simulations
for (sim in 1:n_sim){
#Now, we are going to simulate the time series
#1. Serie AR(3) con funci칩n seno
x1<-rnorm(3,0,20)
for (i in 4:size){
x1<-append(x1,3*sin(x1[i-1])+2*sin(x1[i-2])+sin(x1[i-3])+rnorm(1))
}
#2. AR(4) con funciones sin(x)
x2<-rnorm(4,0,1)
for (i in 4:size){
x2<-append(x2,3*sin(x2[i-1])+2*sin(x2[i-2]/3)+0.5*sin(x2[i-3]/2)-3*1/(1+exp(x2[i-4]))+rnorm(1))
}
#3.ARIMA(2,1,1)
x3<-arima.sim(list(2,1,1),n=size)
#4. ARMA FUNCIONAL (2,2)
x4<-rnorm(2,2,10)
error<-rnorm(2)
for (i in 3:size){
error2<-rnorm(1,0,0.2)
nuevox<-2*cos(x4[i-1])+0.5*sin(x4[i-2])+0.4*error[i-1]+0.8*1/(1+exp(error[i-2]))+error2
error<-append(error,error2)
x4<-append(x4,nuevox)
}
#5. Simulamos un SETAR
TvarMat <- c(2.9,-0.4,-0.1,-1.5, 0.2,0.3)
x5<-setar.sim(n=size,B=TvarMat,lag=2, type="simul", nthresh=1, Thresh=2, starting=c(2.8,2.2))
series<-data.frame(x1=x1,x2=x2,x3=x3,x4=x4,x5=x5)
n_serie=0
for (serie in colnames(series)){
x<-series[[serie]]
n_serie<-n_serie+1
corPearson<-c()
corSpearman<-c()
corKendall<-c()
corXi<-c()
for (lag in 1:lag.max){
update_progress((n_size-1)*(n_sim)*ncol(series)*lag.max+(sim-1)*lag.max*ncol(series) + (n_serie - 1)*lag.max + lag, length(sizes)*n_sim*ncol(series)*lag.max)
data<-data.frame()
#Construction of the matrix with lag columns
for (i in 0:(length(x)-lag-1)){
xt<-x[(length(x)-i)]
xt1<-t(data.frame(rev(x[(length(x)-(lag)-i):(length(x)-(i+1))])))
data<-rbind(data,cbind(xt,xt1))
}
#Modify the data frame created
row.names(data)<-0:(nrow(data)-1)
VarReg<-paste0("x",1:(lag))
colnames(data)<-c("xt",VarReg)
#calculate each kind of correlation of the matrix
corP<-pcor(data,method="pearson")
corSp<-pcor(data,method="spearman")
corK<-pcor(data,method="kendall")
corX<-partcor(data,method = "xi")
#Since we are only interested in the correlation with xt, we only consider the first row
corP<-corP$estimate[1,]
corSp<-corSp$estimate[1,]
corK<-corK$estimate[1,]
corX<-corX[1,]
corPearson<-append(corPearson, corP[lag+1])
corSpearman<-append(corSpearman,corSp[lag+1])
corKendall<-append(corKendall,corK[lag+1])
corXi<-append(corXi,corX[lag+1])
#print(paste("|--lag ",lag,"/",lag.max ,"|--serie",serie, "|--simulation ",sim,"/",n_sim," |-- size",size))
}
#Confidence intervals
#For Pearson the variance is 1/N
Plags<-data.frame(lag=(index(corPearson)-1),value=corPearson)
#plot(corPearson[1:lag],type="h")
#abline(h=qnorm(0.975)*sqrt(1/size))
#abline(h=-qnorm(0.975)*sqrt(1/size))
Plags<-Plags[abs(Plags$value)>qnorm(0.975)*sqrt(1/size),]
Plags<-Plags$lag
npp<-length(Plags)
pp<-rbind(pp,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(npp>=1, Plags[[length(Plags)]], 0),p2=ifelse(npp>=2, Plags[(length(Plags)-1)], 0),p3=ifelse(npp>=3, Plags[(length(Plags)-2)], 0)))
#For Spearman the variance is 1/(N-1)
#plot(corSpearman,type="h")
#abline(h=-qnorm(0.975)*sqrt(1/(size-1)))
#abline(h=qnorm(0.975)*sqrt(1/(size-1)))
SPlags<-data.frame(lag=(index(corSpearman)-1),value=corSpearman)
SPlags<-SPlags[abs(SPlags$value)>qnorm(0.975)*sqrt(1/(size-1)),]
SPlags<-SPlags$lag
nsp<-length(SPlags)
psp<-rbind(psp,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(nsp>=1, SPlags[[length(SPlags)]], 0),p2=ifelse(nsp>=2, SPlags[(length(SPlags)-1)], 0),p3=ifelse(nsp>=3, SPlags[(length(SPlags)-2)], 0)))
#For Kendall the variance is 2(2n+5)/9n(n-1)
#plot(corKendall[1:lag],type="h")
#abline(h=qnorm(0.975)*sqrt(2*(2*size+5)/(9*size*(size-1))))
#abline(h=-qnorm(0.975)*sqrt(2*(2*size+5)/(9*size*(size-1))))
Klags<-data.frame(lag=(index(corKendall)-1),value=corKendall)
Klags<-Klags[abs(Klags$value)>(qnorm(0.975)*sqrt(2*(2*size+5)/(9*size*(size-1)))),]
Klags<-Klags$lag
nk<-length(Klags)
pk<-rbind(pk,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(nk>=1, Klags[[length(Klags)]], 0),p2=ifelse(nk>=2, Klags[[(length(Klags)-1)]], 0),p3=ifelse(nk>=3, Klags[[(length(Klags)-2)]], 0)))
#For Xi the variance is 2/5N
#plot(corXi[1:lag],type="h")
#abline(h=qnorm(0.975)*sqrt(2/(5*size)),col="red",lw=1)
#abline(h=-qnorm(0.975)*sqrt(2/(5*size)),col="red",lw=1)
#Get the 3 maximum autocorrelations
Xilags<-data.frame(lag=(index(corXi)-1),value=corXi)
Xilags<-Xilags[abs(Xilags$value)>(qnorm(0.975)*sqrt(2/(5*size))),]
Xilags<-Xilags$lag#[(nrow(Xilags)-2):nrow(Xilags)]
nxi=length(Xilags)
pxi<-rbind(pxi,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(nxi>=1, Xilags[[length(Xilags)]], 0),p2=ifelse(nxi>=2, Xilags[[(length(Xilags)-1)]], 0),p3=ifelse(nxi>=3, Xilags[[(length(Xilags)-2)]], 0)))
#codecM<-append(codecM,codec(data[,1],data[,ncol(data)],data[,2:(ncol(data)-1)]))
#Now, with the coefficient of Azadka-Chatterjee
codecM<-foci(data$xt,data[2:(lag+1)],numCores = 1)
codecM<-codecM$selectedVar$index
ncodec=length(codecM)
pcodec<-rbind(pcodec,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(ncodec>=1, max(codecM), 0),p2=ifelse(ncodec>=2, sort(codecM, TRUE)[2], 0),p3=ifelse(ncodec>=3,sort(codecM, TRUE)[3], 0)))
} #End series iterations
} #End simulations
}#End sizes
cat("\n")
View(pp)
#Fixed terms
n_sim=200
lag.max=30
pp=NULL
psp=NULL
pk=NULL
pxi=NULL
pcodec<-NULL
sizes<-c(100,500,1000,2000,5000,10000)
n_size=0
for (size in sizes){
n_size=n_size+1
#Simulations
for (sim in 1:n_sim){
#Now, we are going to simulate the time series
#1. Serie AR(3) con funci칩n seno
x1<-rnorm(3,0,20)
for (i in 4:size){
x1<-append(x1,3*sin(x1[i-1])+2*sin(x1[i-2])+sin(x1[i-3])+rnorm(1))
}
#2. AR(4) con funciones sin(x)
x2<-rnorm(4,0,1)
for (i in 4:size){
x2<-append(x2,3*sin(x2[i-1])+2*sin(x2[i-2]/3)+0.5*sin(x2[i-3]/2)-3*1/(1+exp(x2[i-4]))+rnorm(1))
}
#3.ARIMA(2,1,1)
x3<-arima.sim(list(2,1,1),n=size)
#4. ARMA FUNCIONAL (2,2)
x4<-rnorm(2,2,10)
error<-rnorm(2)
for (i in 3:size){
error2<-rnorm(1,0,0.2)
nuevox<-2*cos(x4[i-1])+0.5*sin(x4[i-2])+0.4*error[i-1]+0.8*1/(1+exp(error[i-2]))+error2
error<-append(error,error2)
x4<-append(x4,nuevox)
}
#5. Simulamos un SETAR
TvarMat <- c(2.9,-0.4,-0.1,-1.5, 0.2,0.3)
x5<-setar.sim(n=size,B=TvarMat,lag=2, type="simul", nthresh=1, Thresh=2, starting=c(2.8,2.2))
series<-data.frame(x1=x1,x2=x2,x3=x3,x4=x4,x5=x5)
n_serie=0
for (serie in colnames(series)){
x<-series[[serie]]
n_serie<-n_serie+1
corPearson<-c()
corSpearman<-c()
corKendall<-c()
corXi<-c()
for (lag in 1:lag.max){
update_progress((n_size-1)*(n_sim)*ncol(series)*lag.max+(sim-1)*lag.max*ncol(series) + (n_serie - 1)*lag.max + lag, length(sizes)*n_sim*ncol(series)*lag.max)
data<-data.frame()
#Construction of the matrix with lag columns
for (i in 0:(length(x)-lag-1)){
xt<-x[(length(x)-i)]
xt1<-t(data.frame(rev(x[(length(x)-(lag)-i):(length(x)-(i+1))])))
data<-rbind(data,cbind(xt,xt1))
}
#Modify the data frame created
row.names(data)<-0:(nrow(data)-1)
VarReg<-paste0("x",1:(lag))
colnames(data)<-c("xt",VarReg)
#calculate each kind of correlation of the matrix
corP<-pcor(data,method="pearson")
corSp<-pcor(data,method="spearman")
corK<-pcor(data,method="kendall")
corX<-partcor(data,method = "xi")
#Since we are only interested in the correlation with xt, we only consider the first row
corP<-corP$estimate[1,]
corSp<-corSp$estimate[1,]
corK<-corK$estimate[1,]
corX<-corX[1,]
corPearson<-append(corPearson, corP[lag+1])
corSpearman<-append(corSpearman,corSp[lag+1])
corKendall<-append(corKendall,corK[lag+1])
corXi<-append(corXi,corX[lag+1])
#print(paste("|--lag ",lag,"/",lag.max ,"|--serie",serie, "|--simulation ",sim,"/",n_sim," |-- size",size))
}
#Confidence intervals
#For Pearson the variance is 1/N
Plags<-data.frame(lag=(index(corPearson)-1),value=corPearson)
#plot(corPearson[1:lag],type="h")
#abline(h=qnorm(0.975)*sqrt(1/size))
#abline(h=-qnorm(0.975)*sqrt(1/size))
Plags<-Plags[abs(Plags$value)>qnorm(0.975)*sqrt(1/size),]
Plags<-Plags$lag
npp<-length(Plags)
pp<-rbind(pp,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(npp>=1, Plags[[length(Plags)]], 0),p2=ifelse(npp>=2, Plags[(length(Plags)-1)], 0),p3=ifelse(npp>=3, Plags[(length(Plags)-2)], 0)))
#For Spearman the variance is 1/(N-1)
#plot(corSpearman,type="h")
#abline(h=-qnorm(0.975)*sqrt(1/(size-1)))
#abline(h=qnorm(0.975)*sqrt(1/(size-1)))
SPlags<-data.frame(lag=(index(corSpearman)-1),value=corSpearman)
SPlags<-SPlags[abs(SPlags$value)>qnorm(0.975)*sqrt(1/(size-1)),]
SPlags<-SPlags$lag
nsp<-length(SPlags)
psp<-rbind(psp,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(nsp>=1, SPlags[[length(SPlags)]], 0),p2=ifelse(nsp>=2, SPlags[(length(SPlags)-1)], 0),p3=ifelse(nsp>=3, SPlags[(length(SPlags)-2)], 0)))
#For Kendall the variance is 2(2n+5)/9n(n-1)
#plot(corKendall[1:lag],type="h")
#abline(h=qnorm(0.975)*sqrt(2*(2*size+5)/(9*size*(size-1))))
#abline(h=-qnorm(0.975)*sqrt(2*(2*size+5)/(9*size*(size-1))))
Klags<-data.frame(lag=(index(corKendall)-1),value=corKendall)
Klags<-Klags[abs(Klags$value)>(qnorm(0.975)*sqrt(2*(2*size+5)/(9*size*(size-1)))),]
Klags<-Klags$lag
nk<-length(Klags)
pk<-rbind(pk,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(nk>=1, Klags[[length(Klags)]], 0),p2=ifelse(nk>=2, Klags[[(length(Klags)-1)]], 0),p3=ifelse(nk>=3, Klags[[(length(Klags)-2)]], 0)))
#For Xi the variance is 2/5N
#plot(corXi[1:lag],type="h")
#abline(h=qnorm(0.975)*sqrt(2/(5*size)),col="red",lw=1)
#abline(h=-qnorm(0.975)*sqrt(2/(5*size)),col="red",lw=1)
#Get the 3 maximum autocorrelations
Xilags<-data.frame(lag=(index(corXi)-1),value=corXi)
Xilags<-Xilags[abs(Xilags$value)>(qnorm(0.975)*sqrt(2/(5*size))),]
Xilags<-Xilags$lag#[(nrow(Xilags)-2):nrow(Xilags)]
nxi=length(Xilags)
pxi<-rbind(pxi,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(nxi>=1, Xilags[[length(Xilags)]], 0),p2=ifelse(nxi>=2, Xilags[[(length(Xilags)-1)]], 0),p3=ifelse(nxi>=3, Xilags[[(length(Xilags)-2)]], 0)))
#codecM<-append(codecM,codec(data[,1],data[,ncol(data)],data[,2:(ncol(data)-1)]))
#Now, with the coefficient of Azadka-Chatterjee
codecM<-foci(data$xt,data[2:(lag+1)],numCores = 1)
codecM<-codecM$selectedVar$index
ncodec=length(codecM)
pcodec<-rbind(pcodec,data.frame(size=size,sim=sim, serie=serie,p1=ifelse(ncodec>=1, max(codecM), 0),p2=ifelse(ncodec>=2, sort(codecM, TRUE)[2], 0),p3=ifelse(ncodec>=3,sort(codecM, TRUE)[3], 0)))
} #End series iterations
} #End simulations
}#End sizes
save.image("~/Universidad/2024-1/Trabajo de Grado/Trabajo de Grado 2024-1S Juan Pablo Monta침o-20240306T200844Z-001/Trabajo de Grado 2024-1S Juan Pablo Monta침o/AlgoTuil2.RData")
library(readr)
library(dplyr)
library(readxl)
library(writexl)
library(zoo)
library(ggplot2)
#Load the data of percentage variation of births
data = read.csv("data/Variation_of_births.csv", sep = ";")
#Load the estimated total fecundity Rates (TFR)
TFE<-read_csv("data/wcde_data.csv",skip=8)
#At the end, we didn't consider Cuba in the study. Let's remove it from the database
TFE<-TFE[TFE$Area!="Cuba",]
YearsStudy <- function(YearsStudy) {
if (YearsStudy %in% c("No Education", "Incomplete Primary", "Primary")) {
return("at most 7")
} else if (YearsStudy %in% c("Lower Secondary", "Upper Secondary")) {
return("8-11")
} else if (YearsStudy %in% c("Post Secondary")) {
return("12 or more")
} else {
return(NA) # In case that there is another value
}
}
info_variable <- function(variable){
#1.Get the years of study.
# There are 3 possibel categories code as "07", "8" and "12" in the name of the column
if (substr(variable,2,2)=="8"){
StudyYears<-substr(variable,2,2)
}else{StudyYears <- substr(variable, 2, 3)}
#2. Now we are going to get the country of the variable.
#First we create a dictionary to interpret the country codes
CountryLetter <- c("B" = "Brazil", "CR" = "Costa Rica", "M" = "Mexico", "CB" = "Cuba", "CH"="Chile")
# Get the position (index) of the character that refers to the country in the column name
InitialCountryPosition <- ifelse(StudyYears == "8", 3,4)
# Get the country codes
country_code <- substr(variable, InitialCountryPosition, ifelse(substr(variable, InitialCountryPosition + 1, InitialCountryPosition + 1) %in% c("0", "1", "2", "3", "4", "5", "6", "7", "8", "9"), InitialCountryPosition, InitialCountryPosition + 1))
# Interpret the country code using the dictionary
country <- ifelse(country_code %in% names(CountryLetter), CountryLetter[country_code], "Otro")
# 3. Get the age group, which in most of the cases are the last 4 characters of the column name
#   the group 40+ will be identified in a different way
Age2 <- substr(variable, nchar(variable) - 1, nchar(variable))
Age1 <- substr(variable, nchar(variable) - 3, nchar(variable)-2)
# Get the interpretation of each StudyYears code-abbreviation
if (StudyYears=="07"){
text<-"at most 7"}else{if(StudyYears=="8"){text<-"8-11"}else{text<-"12 or more"}}
# return all the information obtained in a vector
return(c(StudyYears = text, country = country, Age1 = Age1,Age2=Age2))
}
#For practical use, we will create functions to obtain the country, age and study independently
country<-function(Variable){info_variable(Variable)[2]}
study_years<-function(Variable){info_variable(Variable)[1]}
Age<-function(Variable){
#Here, we take in count the only Age group that is not coded in 4 characters, that is "40+"
Age2<-info_variable(Variable)[4]
if (Age2=="40"){return("40+")}else{
paste(info_variable(Variable)[3],"-",info_variable(Variable)[4])}
}
TFE$Rate<-TFE$Rate/1000
TFE<-TFE %>% mutate(Age=gsub("--"," - ",Age))
TFE[TFE$Age%in%c("40 - 44","45 - 49"),]["Age"]<-"40+"
#Now, we sum the rates grouped by the values in the other columns. This is made to sum the rates of the 2 categories that were merged
TFE<-aggregate(Rate~ Area+Period+Age+ Education,data=TFE,FUN=sum)
TFE["Years_Study"]<-(sapply(TFE$Education,YearsStudy))
Rates <- aggregate(Rate ~ Area+Age+ Years_Study, data = TFE, FUN = mean)
ReferenceDate<-data[data$Mes=="2022-07",]
View(Rates)
ReferenceDate<-data[data$Mes=="2022-07",]
ReferenceDate2<-data[data$Mes=="2021-07",]
year2022<-data[data$Mes>=as.yearmon("2022-1"),]
year2021<-data[data$Mes>=as.yearmon("2021-1") & data$Mes<as.yearmon("2022-1"),]
#Now, lets create a table with the variation of TFR by country
Variation<-NULL
for (Column in colnames(ReferenceDate)[2:length(colnames(ReferenceDate))]){
Ag<-Age(Column)
Pa<-country(Column)[[1]]
if (Pa %in% c("Chile","Cuba")){
Var<-ReferenceDate2[[Column]] #Variation of the specific month
MeanVar<-colMeans(year2021[2:91])
MeanVar<-MeanVar[[Column]] #Mean variation of 2021
}else{
Var<-ReferenceDate[[Column]]
MeanVar<-colMeans(year2022[2:91])
MeanVar<-MeanVar[[Column]]}
Stu<-study_years(Column)[[1]]
Fila<-data.frame(Area=Pa,Age=Ag,Years_Study=Stu,Var=Var, MeanVar=MeanVar)
Variation<-rbind(Variation,Fila)
}
Variation[!(Variation$Age %in% c("15 - 19","20 - 24","25 - 29","30 - 34","35 - 39")),]["Age"]<-"40+"
#remove Cuba an outer countries that does not have any data.
Variation<-na.omit(Variation)
#Apply the pandemic on the TFR pf each group
Rates<-merge(Rates,Variation, by=c("Area","Age","Years_Study"))
Rates["WithEffect"]<-Rates$Rate*(1+Rates$Var/100)
Rates["WithEffectMean"]<-Rates$Rate*(1+Rates$MeanVar/100)
#Calculate the TFR without the effect of the pandemic
TFRProjected<-aggregate(Rate~Area+Years_Study,data=Rates,FUN=sum)
TFRProjected$Rate<-TFRProjected$Rate*5
#Calculate the TFR with the effect of the pandemic
TFRWithPandemic<-aggregate(WithEffect~Area+Years_Study,data=Rates,FUN=sum) #considering july
TFRWithPandemicMean<-aggregate(WithEffectMean~Area+Years_Study,data=Rates,FUN=sum) #considering the mean variation pf 2022
TFRWithPandemic$WithEffect<-TFRWithPandemic$WithEffect*5 #Each age group has a length of 5
TFRWithPandemicMean$WithEffectMean<-TFRWithPandemicMean$WithEffectMean*5
#Make a joint table of the TFR to make comparison easier.
TFR<-merge(TFRProjected,TFRWithPandemic,by=c("Area","Years_Study"))
TFR<-merge(TFR,TFRWithPandemicMean,by=c("Area","Years_Study"))
TFR<-TFR%>% arrange(Area,desc(Years_Study))
View(TFR)
View(pcodec)
a<-pcodec[pcodec$size==1000 & pcodec$serie=="x1",]
View(a)
hist(a$p1)
boxplot(a$p1)
median(a$p1)
median(a$p2)
median(a$p3)
mean(a$p1)
a<-pcodec[pcodec$size==1000 & pcodec$serie=="x1",]
b<-pp[pp$size==1000 & pp$serie=="x1",]
mean(b$p1)
median(b$p1)
boxplot(b$p1)
hist(b$p1)
hist(b$p2)
boxplot(b$p2)
median(b$p2)
mean(b$p2)
mean(b$p3)
median(b$p3)
hist(b$p3)
View(TFRProjected)
View(TFR)
p <- ggplot(pcodec, aes(x=size, y=p1)) +
geom_violin()
p
p <- ggplot(pcodec, aes(x=size, y=p1)) +
geom_violin(trim = F)+geom_boxplot(width=0.1)
p
p <- ggplot(pcodec, aes(x=factor(size), y=p1,fill=serie)) +
geom_violin(trim = F)+geom_boxplot(width=0.1)
p
p <- ggplot(pcodec, aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.1)
p
#p <-
ggplot(pcodec, aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.01)
ggplot(pp, aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
#p <-
ggplot(pcodec, aes(x=factor(size), y=p1,fill=serie)) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
#p <-
ggplot(pcodec[pcodec$serie=="x1"], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
#p <-
ggplot(pcodec[pcodec$serie=="x1",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
#p <-
ggplot(pcodec[pcodec$serie=="x1",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.025)
ggplot(pp[pp$serie=="x1",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(psp[psp$serie=="x1",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(pk[pk$serie=="x1",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(pxi[pxi$serie=="x1",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
#p <-
ggplot(pcodec[pcodec$serie=="x3",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.025)
ggplot(pp[pp$serie=="x3",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(pp[pp$serie=="x3",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(psp[psp$serie=="x3",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(pk[pk$serie=="x3",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(pxi[pxi$serie=="x3",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
#p <-
ggplot(pcodec[pcodec$serie=="x4",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.025)
ggplot(pp[pp$serie=="x4",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(psp[psp$serie=="x4",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(pk[pk$serie=="x4",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(pxi[pxi$serie=="x4",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(pp[pp$serie=="x4",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
#p <-
ggplot(pcodec[pcodec$serie=="x5",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.025)
ggplot(pp[pp$serie=="x5",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(psp[psp$serie=="x5",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(pk[pk$serie=="x5",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(pxi[pxi$serie=="x5",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
ggplot(pp[pp$serie=="x5",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
#p <-
ggplot(pcodec[pcodec$serie=="x5",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.025)
#p <-
ggplot(pcodec[pcodec$serie=="x5",], aes(x=factor(size), y=p1,fill=factor(size))) +
geom_violin(trim = F)+geom_boxplot(width=0.05)
